Dataset: 一般来说只写自己的 dataset

Dataloader：一般用默认的就行，num_workers 在 dataloader 里面一般最好设置成与机器的 CPU 核心数量相等/相似能享受到比较好的速度。默认是0，这个时候只使用主进程，设为1或以上会创建相应的*额外* subprocess 来处理

需要包含的流程：
1. candidate generation (recall)
2. ranking
3. reranking
4. 日志处理 + 外部监控 + 策略迭代

Fidelity News 有一个专属于你的主界面，你对这个页面的用户停留时长负责人均观看时长（10来分钟）人均观看条数（30条）

模型训练的目标是：点击率，转发率，但是用户在你这个页面的人均停留时长是你的一个主要目标

排序网络结构：DIN 和 MoE 用过吗

**接到新闻推荐这个项目的时候，你是怎么梳理它的，以及在这个过程中你做了哪些事情，以及你接下来对他的一个规划？**

# 训练策略迭代

- 模型一天/三天一更新，DAU达不到的话意义不太大
- 模型自动更新小时级
- 用户分层：新老用户

# 算法模型上的迭代

- XGBoost 能力达不到 => DIN => MMoE

# 特征工程处理

- 多少字段，哪些是比较有效果/有价值的
- 用户，新闻

链路：
用户 -> 召回百万条新闻 -> 排序千 -> 重排

新闻有不同的类别：新闻画像
有用户分层：用户画像
增量画像的池子 cross fit 做特征

-> FCN -> reranking

mini max 做大模型蒸馏

-大模型我同样都是7b，有的7b说能在比如说24G4090上我能跑起来，然后有的说我就必须得到32G或者64G里跑起来，这是为什么呢？一个7b的完全体版本，可能我要在32g才能够运行起来，但是现在如果我直接想让它在一个24g运行起来，有什么办法？

zero-shot few-shot，怎么调提示词

open AI的时候，它其实是有对应的接口对吧？里边会有多个字段，比如system prompt，比如说assistant对吧？这些对应字段是你需要填什么样的内容，就是这些字段它代表什么含义？

像你说的其实属于风控领域的风控领域一个评论审核的操作，它相当于我最后就是个二分类，但这个二分类就像你说的，我既然可以有bert之后，我可以先去提供一个底模，然后拿这个底模的话，然后我在少量的数据集上做微调就可以了，这个微调其实也蛮简单，我们主要让专家系统，都不用专家，我们只要让审核人员帮我们准备n条正常的和n条异常的扔进去，然后这样我们就可以直接自动化的训练出来一个bert模型，而现在自自动化训练出来一个分类模型，其实也是bert后边加classifier，然后这样操作之后，我们不就比你现在这个操作要更精准，而且会有带来准招，就是说我知道我离线的指标情况是如何，然后我可以不断添加数据提高的准招，最后保持我模型越来越好，传统方法我们姑且不算大模型，就算传统方法已经可以做到一个蛮自动化的一个操作了，这个时候大模型的引入它真的会有商业价值吗？（我们做的classifier并不是最后YouTube实践中在用的classifier，其实我们只是相当于给了他一个伪的label，让他能够像你说的那样用一个真正的模型去训练，我们其实只是给没有label的数据给他打label，就我们严重怀疑这一个评论是有害的，因为美国人工很贵，如果让标注人去标注这些数据，评论实在太多了，其实他看不过来。